{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tri Cities Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import linalg\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from numpy import random\n",
    "import inspect\n",
    "import sys\n",
    "import weakref\n",
    "from EpiCommute import SIRModel\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "np.set_printoptions(precision = 5, suppress = True, linewidth = 100)\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import interactive, interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highway is a class that holds the weight of the pathway between cities and all of the connections formed by the highway\n",
    "class Highway:\n",
    "    instances=[]\n",
    "    def __init__(self,name,weight=0,cities=np.array([[]])):\n",
    "        self.__class__.instances.append(self)\n",
    "        self.name=name\n",
    "        self.weight=weight\n",
    "        self.cities=cities\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#City simply holds the population and location of each city\n",
    "class City:\n",
    "    instances=[]\n",
    "    def __init__(self,name,pop=0,loc=[0,0]):\n",
    "        self.__class__.instances.append(self)\n",
    "        self.name=name\n",
    "        self.pop=pop\n",
    "        self.loc=loc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring Cities(populations and locations are accurate)\n",
    "Johnson_City = City('Johnson_City',66515,[36.3345,-82.3703])\n",
    "Bristol =City('Bristol',26852,[36.5951,-82.1887])\n",
    "Jonesborough = City('Jonesborough',5247,[36.2943,-82.4735])\n",
    "Elizabethton = City('Elizabethton',13577,[36.3487,-82.2107])\n",
    "Gray= City('Gray',1016,[36.4172,-82.4720])\n",
    "Kingsport = City('Kingsport',53376,[36.5484,-82.5618])\n",
    "#Declaring Highways\n",
    "I_26 = Highway('I_26',63665,np.array([['Kingsport','Gray'],['Gray','Johnson_City']]))\n",
    "I_81 = Highway('I_81',40277,np.array([['Gray','Bristol']]))\n",
    "Three_21=Highway('Three_21',26322,np.array([['Jonesborough','Johnson_City'],['Johnson_City','Elizabethton']]))\n",
    "Nineteen_e = Highway('Nineteen_e',9370,np.array([['Elizabethton','Bristol']]))\n",
    "Eleven_w = Highway('Eleven_w',16644,np.array([['Kingsport','Bristol']]))\n",
    "Seventy_Five=Highway('Seventy_Five',5762,np.array([['Gray','Jonesborough']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre_Highway_List=[]\n",
    "for instance in Highway.instances:\n",
    "    Pre_Highway_List.append(instance.name)\n",
    "#Remove duplicates\n",
    "    Highway_List=[]\n",
    "for i in Pre_Highway_List:\n",
    "    if i not in Highway_List:\n",
    "        Highway_List.append(i)\n",
    "Highway_List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup\n",
    "\n",
    "## Create Graph\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "#Create Tri_Cities Graph\n",
    "Tri_Cities = nx.Graph()\n",
    "#Nodes are connected with self via random weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Populate the graph with weighted edges using the list of highways\n",
    "for a in range(len(Highway_List)):\n",
    "    HW=globals()[Highway_List[a]]\n",
    "    for b in range(len(HW.cities)):\n",
    "        Tri_Cities.add_edge(HW.cities[b][0],HW.cities[b][1],weight=HW.weight)\n",
    "list(Tri_Cities.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_array=np.zeros(len(Tri_Cities.nodes))#pop_array lists the populations of all cities\n",
    "for a in range(len(Tri_Cities.nodes)):\n",
    "    pop_array[a]=eval(list(Tri_Cities.nodes)[a]).pop\n",
    "pop_array  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pop = pop_array/sum(pop_array)\n",
    "mobility_1=nx.adj_matrix(Tri_Cities).toarray()#create weighted transition matrix\n",
    "mobility_t=np.zeros((6,6))\n",
    "for a in range(6):\n",
    "    mobility_t[a,:]=mobility_1[a]/sum(mobility_1[a])\n",
    "mobility_t\n",
    "difff= 3# diff will represent the output of the cost function later\n",
    "for z in range(500):#z will represent the scaler multiple of the population array for SAH weights\n",
    "    rand=pop_array*.1*z/max(pop_array)\n",
    "    mobility_2 =mobility_t+np.diag(rand)\n",
    "    mobility_2\n",
    "    for a in range(6):\n",
    "        mobility_2[a,:]=mobility_2[a,:]/sum(mobility_2[a,:])#normalize transition matrix\n",
    "    eigs=np.linalg.eig(mobility_2.T)\n",
    "    whereat=np.where(abs(eigs[0]-1)<.01)[0][0]# find dominant eigenvector\n",
    "    stab_dist=eigs[1][:,whereat]/sum(eigs[1][:,whereat])\n",
    "    if(sum((stab_dist-norm_pop)*(stab_dist-norm_pop))<difff):# use ols to find the lowest cost function\n",
    "        answer=rand\n",
    "        difff=sum((stab_dist-norm_pop)*(stab_dist-norm_pop))\n",
    "    \n",
    "mobility_2=mobility_t +np.diag(answer)\n",
    "for a in range(6):\n",
    "    mobility_2[a,:]=mobility_2[a,:]/sum(mobility_2[a,:])\n",
    "mobility_2# normalized final transition matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outbreak source is city of our choice\n",
    "\n",
    "examples={}# examples will save variations\n",
    "\n",
    "City_List=list(Tri_Cities.nodes())\n",
    "# Initialize the model\n",
    "variations=100\n",
    "for a in range(6):\n",
    "    for b in range(variations):\n",
    "        model = SIRModel(\n",
    "            mobility_2,#transition matrix\n",
    "            pop_array,#susbpopulations sizes\n",
    "            outbreak_source=a,\n",
    "            mu=1/8,# recovery rate\n",
    "            R0= 2.5,        \n",
    "            dt=0.1,               # time interval \n",
    "            dt_save=1/6,            # when to save observables\n",
    "            I0=400,# initial infected\n",
    "            VERBOSE=True\n",
    "               \n",
    "                                \n",
    "            )\n",
    "        examples['result'+str(b)+list(Tri_Cities.nodes())[a]]=model.run_simulation()\n",
    "  #save results of simulations \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=list(examples)\n",
    "examples\n",
    "#names saves the names of all elements in \"examples\". This allows the dictionary to be more easily accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "results['I']=0\n",
    "results['R']=0\n",
    "results['S']=0\n",
    "for a in range(6*variations):\n",
    "        results['I']+=(1/(6*variations))*np.array(examples[names[a]]['I'])\n",
    "        results['R']+=(1/(6*variations))*np.array(examples[names[a]]['R'])\n",
    "        results['S']+=(1/(6*variations))*np.array(examples[names[a]]['S'])\n",
    "for a in range(6):\n",
    "    results[City_List[a]+'I_total']=0\n",
    "    results[City_List[a]+'R_total']=0\n",
    "    results[City_List[a]+'S_total']=0\n",
    "    for b in range(variations):\n",
    "        results[City_List[a]+'I_total']+=(1/variations)*np.array(examples[names[a*variations +b]]['I_total'])\n",
    "        results[City_List[a]+'R_total']+=(1/variations)*np.array(examples[names[a*variations +b]]['R_total'])\n",
    "        results[City_List[a]+'S_total']+=(1/variations)*np.array(examples[names[a*variations +b]]['S_total'])\n",
    "print(results['I'])\n",
    "        #results is an average of all variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(np.where(results['Johnson_CityI_total']>.25)[0]>0):\n",
    "    beginning=np.where(results['Johnson_CityI_total']>.25)[0][0]\n",
    "    end=np.where(results['Johnson_CityI_total']>.25)[0][-1]        \n",
    "    amount=results['Johnson_CityR_total'][end]-results['Johnson_CityR_total'][beginning]\n",
    "else:\n",
    "    amount=0\n",
    "amount\n",
    "# This section calculates the percentage of people infected that are above the estimated hospital capacity of 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities={}# cities saves the products of research based on which city is the outbreak source\n",
    "stds={}# will be used to save standard deviation\n",
    "means={}# will be used to save means\n",
    "for a in range(6):# iterated over 6 because there are 6 cities\n",
    "    cities[City_List[a]+\"endvec\"]=np.array([])\n",
    "    cities[City_List[a]+\"maxvec\"]=np.array([])\n",
    "    cities[City_List[a]+\"infectedvec\"]=np.array([])\n",
    "    for b in range(variations):\n",
    "        current=examples['result'+str(b)+City_List[a]]\n",
    "        c_S=np.array(current['S']).T[a]#saves susceptible, infected, recovered for each data set\n",
    "        c_I=np.array(current['I']).T[a]\n",
    "        c_R=np.array(current['R']).T[a]\n",
    "        mx=max(c_I)*sum(pop_array)#maximum infected at once\n",
    "        I_t = c_R[len(c_R)-1]*sum(pop_array)#total infected\n",
    "        Half_life= np.where(np.cumsum(c_I)<.5*np.cumsum(c_I))[len(c_I)-1][0]# half the time required for the epidemic to occur\n",
    "        Half_life=Half_life[len(Half_life)-1]\n",
    "        cities[City_List[a]+\"endvec\"]=np.append(cities[City_List[a]+\"endvec\"],2*Half_life)# saves the end points for the epidemic\n",
    "        cities[City_List[a]+\"infectedvec\"]=np.append(cities[City_List[a]+\"infectedvec\"],I_t)#saves the total infeced\n",
    "        cities[City_List[a]+\"maxvec\"]=np.append(cities[City_List[a]+\"maxvec\"],mx)#saves maximum infected at one time\n",
    "    stds[str(City_List[a])+'endvecstd']=np.std(cities[City_List[a]+\"endvec\"])#stanard deviation and mean are found for all\n",
    "    means[str(City_List[a])+'endvecmean']=np.mean(cities[City_List[a]+\"endvec\"])\n",
    "    stds[str(City_List[a])+'maxvecstd']=np.std(cities[City_List[a]+\"maxvec\"])\n",
    "    means[str(City_List[a])+'maxvecmean']=np.mean(cities[City_List[a]+\"maxvec\"])\n",
    "    stds[str(City_List[a])+'infectedvecstd']=np.std(cities[City_List[a]+\"infectedvec\"])\n",
    "    means[str(City_List[a])+'infectedvecmean']=np.mean(cities[City_List[a]+\"infectedvec\"])\n",
    "#The following is identical to above, but considers all variations equally\n",
    "totendvec=np.array([])\n",
    "totmaxvec=np.array([])\n",
    "totinfectedvec=np.array([])\n",
    "for b in range(6*variations):\n",
    "    current=examples[names[b]]\n",
    "    c_S=current['S_total']\n",
    "    c_I=current['I_total']\n",
    "    c_R=current['R_total']\n",
    "    mx=max(c_I)*sum(pop_array)\n",
    "    I_t = c_R[len(c_R)-1]*sum(pop_array)\n",
    "    Half_life= np.where(np.cumsum(c_I)<.5*np.cumsum(c_I))[len(c_I)-1][0]\n",
    "    Half_life=Half_life[len(Half_life)-1]\n",
    "    totendvec=np.append(totendvec,2*Half_life)\n",
    "    totinfectedvec=np.append(totinfectedvec,I_t)\n",
    "    totmaxvec=np.append(totmaxvec,mx)\n",
    "stds['totendvecstd']=np.std(totendvec)\n",
    "means['totendvecmean']=np.mean(totendvec)\n",
    "stds['totmaxvecstd']=np.std(totmaxvec)\n",
    "means['totmaxvecmean']=np.mean(totmaxvec)\n",
    "stds['totinfectedvecstd']=np.std(totinfectedvec)\n",
    "means['totinfectedvecmean']=np.mean(totinfectedvec)\n",
    "means\n",
    "totinfectedvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_2 = ['endvec','maxvec','infectedvec']\n",
    "intervals2={}\n",
    "# this section creates 95% confidence intervals for set of variations\n",
    "# this takes the mean and adds/ subtracts 1.96* std\n",
    "for a in range(3):\n",
    "    intervals2['tot'+names_2[a] + 'interval']= [means['tot'+names_2[a]+'mean']-1.96*stds['tot'+names_2[a]+'std'],means['tot'+names_2[a]+'mean']+1.96*stds['tot'+names_2[a]+'std']]\n",
    " \n",
    "for a in range(3):\n",
    "    for b in range(6):\n",
    "        upper=means[list(Tri_Cities.nodes())[b]+names_2[a]+'mean']+1.96*stds[list(Tri_Cities.nodes())[b]+names_2[a]+'std']\n",
    "        lower=means[list(Tri_Cities.nodes())[b]+names_2[a]+'mean']-1.96*stds[list(Tri_Cities.nodes())[b]+names_2[a]+'std']\n",
    "        intervals2[list(Tri_Cities.nodes())[b]+names_2[a] + 'interval']=[lower,upper] \n",
    "\n",
    "print(intervals2)\n",
    "\n",
    "cities_list=list(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(3,figsize=(6.5,10))\n",
    "ax[0].hist(totendvec)\n",
    "ax[0].set_xlabel('Epidemic Length in Days')\n",
    "ax[0].axvline(intervals2['totendvecinterval'][0])\n",
    "ax[0].axvline(intervals2['totendvecinterval'][1])\n",
    "ax[1].hist(totmaxvec)\n",
    "ax[1].set_xlabel('Maximum Infected')\n",
    "ax[1].axvline(intervals2['totmaxvecinterval'][0])\n",
    "ax[1].axvline(intervals2['totmaxvecinterval'][1])\n",
    "ax[2].hist(totinfectedvec)\n",
    "ax[2].set_xlabel('Total Infected')\n",
    "ax[2].axvline(intervals2['totinfectedvecinterval'][0])\n",
    "ax[2].axvline(intervals2['totinfectedvecinterval'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epidemic curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all compartments as a function of time\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rc('figure', dpi=200)\n",
    "#plot SIR.\n",
    "t=examples[names[0]]['t']\n",
    "figure = plt.figure(figsize=(5.5,4))\n",
    "plt.plot(t, results['Johnson_CityS_total'],label='S', color='purple')\n",
    "plt.plot(t, results['Johnson_CityI_total'], label='I', color='firebrick')\n",
    "plt.plot(t, results['Johnson_CityR_total'], label='R', color='k')\n",
    "plt.axhline(.25)# represents the cutoff point for the hospital system\n",
    "plt.legend(frameon=False, loc='center right')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Compartment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spread of infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import rc\n",
    "rc('animation', html='html5')\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates dictionaries for the graph plotting function to access\n",
    "lbls={}\n",
    "for a in range(6):\n",
    "    lbls[list(Tri_Cities.nodes())[a]]=list(Tri_Cities.nodes())[a]\n",
    "poss={}\n",
    "for a in range(6):\n",
    "    poss[City_List[a]]=np.flip(eval(City_List[a]).loc)\n",
    "poss    \n",
    "results['Johnson_CityI_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create animation\n",
    "fig = plt.Figure(figsize = (3,3))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "def f(t=0):\n",
    "    t=2*t\n",
    "    ax.clear()\n",
    "    ax.set_title(t)\n",
    "    ax.set_ylim([36.2,36.7])\n",
    "    ax.set_xlim([-82.65,-82.1])\n",
    "    nx.draw_networkx(Tri_Cities,poss,\n",
    "               with_labels = True,\n",
    "               labels = lbls,\n",
    "               font_size=8,\n",
    "               node_size = 50, \n",
    "               edge_color = 'gray',\n",
    "               node_color = results['I'][t],\n",
    "               cmap = 'Reds', ax  = ax,\n",
    "               vmin = 0,  vmax = 1)\n",
    "    \n",
    "\n",
    "\n",
    "anim =FuncAnimation(fig, f, frames=50, interval=100, \n",
    "                     blit=False, repeat=True)\n",
    "anim\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
